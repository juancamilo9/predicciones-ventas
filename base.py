# -*- coding: utf-8 -*-
"""base.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18yyEuQesfdqqFPqj5a7SuWUbxkP4Etxt
"""

import pandas as pd
import numpy as np
filename = '/content/sales_predictions.csv'
df = pd.read_csv(filename)

df.head()

#  ¿Cuántas filas y columnas?

df.info()

"""# Cuantas Filas y Columnas tiene el DataFrame
Se observa que en total tenemos 12 Columnas y 8522 entradas o filas

# Cuales son los tipos da datos del Dataframe? 


*   Item_Identifier -> Object
*   Item_Weight -> Float64
*   Item_Fat_Content -> object 
*   Item_Visibility -> float64
*   Item_Type -> object 
*   Item_MRP -> float64
*   Outlet_Identifier -> object 
*   Outlet_Establishment_Year -> int64  
*   Outlet_Size ->  object 
*   Outlet_Location_Type -> object 
*   Outlet_Type -> object 
*   Item_Outlet_Sales -> float64



"""

#  ¿Hay duplicados? Si es el caso, eliminen algunos duplicados

df.duplicated().value_counts()

"""Se ha analizado todo el Dataframe en todas sus entradas y no se han encontrado datos duplicados."""

#  ¿Hay duplicados? Si es el caso, eliminen algunos duplicados
df.isna().sum()

"""Tenemos datos faltantes en las siguientes columnas: Item_weight faltan 1463 y representan el 17,16% de los datos y Oulet_Size faltan 2410 Representan el 28,27% de los datos

En este punto, no tengo mucha información para tomar una decición acertada, por un lado, los porcentajes de valores faltantes son altos, por lo cual no es aconsejable imputar datos para rellenar estos, y tampoco es buen punto eliminarlos, la manara mas facil y menos perjudicial es creando categorias de 'Vacios'
"""

# Decidan cómo abordar los valores faltantes y cómo hacerlo. 
#(Esto requiere sus criterios, así que expliquen su elección).
df['Outlet_Size'].value_counts()
# El valor más comun es medium

df['Outlet_Size'].fillna('empty', inplace=True)

df['Outlet_Size'].isna().sum()

"""**Valores faltantes para Item_weight**"""

# introduciremos valores con media(), para mantener el tipo de datos como Float64
median_item_w = df['Item_Weight'].median()
df['Item_Weight'].fillna(median_item_w, inplace=True)
df.isna().sum()

"""#  Encuentren y arreglen alguna categoría inconsistente de datos (example: fix cat, Cat, and cats so that they are consistent)

Actuación sobre las columnas de tipo object
"""

df.info()

df['Item_Identifier'].value_counts()

df['Item_Fat_Content'].value_counts()

"""Para la columna Item_Fat_Content, hay diferentes categorás que al agruparlas pueden dar como resultado más favorable:
 

1.   los registros de tipo 'reg' los agruparé con los registros de 'Regular'
2.   Los registros de tipo 'low fat' , 'LF', son expresiones que dentro se suc pontexto actual significan 'Low Fat', serán agrupadas en una sola.



"""

# Remplazo 'LF' por 'Low Fat'
df['Item_Fat_Content'].replace('LF','Low Fat',inplace=True)
# Remplazo 'low fat' por 'Low Fat'
df['Item_Fat_Content'].replace('low fat','Low Fat',inplace=True)
# Remplazo 'reg' por 'Regular'
df['Item_Fat_Content'].replace('reg','Regular',inplace=True)
df['Item_Fat_Content'].value_counts()

df['Item_Type'].value_counts()

df['Outlet_Identifier'].value_counts()

df['Outlet_Size'].value_counts()

df['Outlet_Location_Type'].value_counts()

df['Outlet_Type'].value_counts()

"""para 'Outlet_Type' Puedo agrupara los tres tipos de supermercado en uno solo llamado 'supermarket'"""

df['Outlet_Type'].replace('Supermarket Type1','Supermarket',inplace=True)
df['Outlet_Type'].replace('Supermarket Type2','Supermarket',inplace=True)
df['Outlet_Type'].replace('Supermarket Type3','Supermarket',inplace=True)
df['Outlet_Type'].value_counts()

"""# Para cualquier columna numérica, obtengan las estadísticas resumidas para cada uno (mínimo, máximo y media)"""

df.info()

df['Item_Weight'].describe()

df['Item_Visibility'].describe()

df['Item_MRP'].describe()

df['Outlet_Establishment_Year'].describe()

df['Item_Outlet_Sales'].describe()